# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://kedro.readthedocs.io/en/stable/data/data_catalog.html

# COMMON SETTINGS

_raw_data_args: &raw_data_args
  type: pandas.GBQQueryDataSet
  project: gid-ml-framework
  layer: raw

_data_args: &data_args
  type: pandas.CSVDataSet
  save_args:
    index: False

_artifact_args: &artifact_args
  type: kedro_mlflow.io.artifacts.MlflowArtifactDataSet

# RAW DATA

ga4_data_train:
  filepath: src/ga4_mlops/pipelines/data_preprocessing/sql/get_ga4_raw_data.sql
  load_args:
    configuration: {
      'query': {
        'parameterMode': 'NAMED',
        'queryParameters': [
            {
                'name': 'start_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210126'}
            },
            {
                'name': 'end_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210128'}
            },
            {
                'name': 'sample_size',
                'parameterType': {'type': 'INT64'},
                'parameterValue': {'value': 10000}
            }
        ]
      }
    }
    reauth: True
  <<: *raw_data_args
  

ga4_data_valid:
  filepath: src/ga4_mlops/pipelines/data_preprocessing/sql/get_ga4_raw_data.sql
  load_args:
    configuration: {
      'query': {
        'parameterMode': 'NAMED',
        'queryParameters': [
            {
                'name': 'start_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210129'}
            },
            {
                'name': 'end_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210129'}
            },
            {
                'name': 'sample_size',
                'parameterType': {'type': 'INT64'},
                'parameterValue': {'value': 2000}
            }
        ]
      }
    }
    reauth: True
  <<: *raw_data_args

ga4_data_test:
  filepath: src/ga4_mlops/pipelines/data_preprocessing/sql/get_ga4_raw_data.sql
  load_args:
    configuration: {
      'query': {
        'parameterMode': 'NAMED',
        'queryParameters': [
            {
                'name': 'start_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210130'}
            },
            {
                'name': 'end_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210130'}
            },
            {
                'name': 'sample_size',
                'parameterType': {'type': 'INT64'},
                'parameterValue': {'value': 2000}
            }
        ]
      }
    }
    
  <<: *raw_data_args

ga4_data_predict:
  filepath: src/ga4_mlops/pipelines/data_preprocessing/sql/get_ga4_raw_data.sql
  load_args:
    configuration: {
      'query': {
        'parameterMode': 'NAMED',
        'queryParameters': [
            {
                'name': 'start_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210131'}
            },
            {
                'name': 'end_date',
                'parameterType': {'type': 'STRING'},
                'parameterValue': {'value': '20210131'}
            },
            {
                'name': 'sample_size',
                'parameterType': {'type': 'INT64'},
                'parameterValue': {'value': 2000}
            }
        ]
      }
    }
  <<: *raw_data_args

# PRIMARY DATA (AFTER: AFTER: SELECTION, AGGREGATION, SAMPLING)

df_train:
  filepath: data/03_primary/df_train.csv
  layer: primary
  <<: *data_args

df_valid:
  filepath: data/03_primary/df_valid.csv
  layer: primary
  <<: *data_args

df_test:
  filepath: data/03_primary/df_test.csv
  layer: primary
  <<: *data_args

df_predict:
  filepath: data/03_primary/df_predict.csv
  layer: primary
  <<: *data_args

# FEATURE DATA (AFTER: FEATURE ENGINEERING, IMPUTATION, ENCODING)

imputers_fitted:
  data_set:
    filepath: data/04_feature/imputers.pkl
    type: pickle.PickleDataSet
  <<: *artifact_args

imputers_stored:
  run_id: ae1e68315431442cb355df49ef3612cd
  data_set:
    filepath: data/04_feature/imputers.pkl
    type: pickle.PickleDataSet
  <<: *artifact_args

feature_encoders_fitted:
  data_set:
    filepath: data/04_feature/feature_encoders.pkl
    type: pickle.PickleDataSet
  <<: *artifact_args

feature_encoders_stored:
  run_id: ae1e68315431442cb355df49ef3612cd
  data_set:
    filepath: data/04_feature/feature_encoders.pkl
    type: pickle.PickleDataSet
  <<: *artifact_args

df_train_fe:
  filepath: data/04_feature/df_train_fe.csv
  layer: feature
  <<: *data_args

df_valid_fe:
  filepath: data/04_feature/df_valid_fe.csv
  layer: feature
  <<: *data_args

df_test_fe:
  filepath: data/04_feature/df_test_fe.csv
  layer: feature
  <<: *data_args

df_predict_fe:
  filepath: data/04_feature/df_predict_fe.csv
  layer: feature
  <<: *data_args

# MODEL INPUT DATA (AFTER: MANUAL FEATURE SELECTION)

abt_train:
  filepath: data/05_model_input/abt_train.csv
  layer: model_input
  <<: *data_args

abt_valid:
  type: pandas.CSVDataSet
  filepath: data/05_model_input/abt_valid.csv
  layer: model_input
  <<: *data_args

abt_test:
  filepath: data/05_model_input/abt_test.csv
  layer: model_input
  <<: *data_args

abt_predict:
  filepath: data/05_model_input/abt_predict.csv
  layer: model_input
  <<: *data_args

# MODELS

model_train:
  data_set:
    type: pickle.PickleDataSet
    filepath: data/06_models/model.pkl
  <<: *artifact_args

model_config:
  data_set:
    type: json.JSONDataSet
    filepath: data/06_models/model_config.json
  <<: *artifact_args

model_predict:
  run_id: ae1e68315431442cb355df49ef3612cd
  data_set:
    type: pickle.PickleDataSet
    filepath: data/06_models/model.pkl
  <<: *artifact_args

# MODEL OUTPUT

predictions:
  filepath: data/07_model_output/predictions.csv
  layer: model_output
  <<: *data_args