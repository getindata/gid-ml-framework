{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext kedro.extras.extensions.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterator, Tuple\n",
    "import re\n",
    "import pickle\n",
    "import _pickle as cPickle\n",
    "\n",
    "from kedro.extras.datasets.pandas import CSVDataSet\n",
    "from kedro.io.core import get_filepath_str\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dgl\n",
    "from dgl.sampling import sample_neighbors, select_topk\n",
    "from dgl import load_graphs, save_graphs, DGLHeteroGraph\n",
    "from dgl.data.heterograph_serialize import HeteroGraphData\n",
    "from typing import Any, Dict, List, Tuple\n",
    "import torch\n",
    "\n",
    "from recommender_gnn.extras.datasets.graph_dataset import DGSRSubGraphsDataSet\n",
    "from recommender_gnn.pipelines.graph_recommendation_modeling.nodes import generate_graph_dgsr, preprocess_dgsr, sample_negatives_dgsr\n",
    "from recommender_gnn.extras.datasets.chunks_dataset import (\n",
    " _concat_chunks,\n",
    ")\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('expand_frame_repr', True)\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.expand_frame_repr', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_graph_path = f\"{dataset}.transactions_graph\"\n",
    "transactions_mapped_path = f\"{dataset}_transactions_mapped\"\n",
    "users_mapping_path = f\"{dataset}_users_mapping\"\n",
    "items_mapping_path = f\"{dataset}_items_mapping\"\n",
    "neg_transactions_path = f\"{dataset}_dgsr_negative_transactions_samples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_mapped = _concat_chunks(context.catalog.load(transactions_mapped_path))\n",
    "neg_transactions = context.catalog.load(neg_transactions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_transactions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DGL graph loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graphs_python(save_filepath: str, graph: dgl.DGLGraph, graph_dict: Dict) -> None:\n",
    "    \"\"\"Save heterographs into file using only Python functions instead of dgl C implementation\"\"\"\n",
    "    if graph_dict is None:\n",
    "        graph_dict = {}\n",
    "    if isinstance(graph, DGLHeteroGraph):\n",
    "        graph = [graph]\n",
    "        graph_dict = [graph_dict]\n",
    "    assert all(\n",
    "        [type(g) == DGLHeteroGraph for g in graph]\n",
    "    ), \"Invalid DGLHeteroGraph in graph argument\"\n",
    "    gdata_list = [\n",
    "        [g, graph_dict[i]] for i, g in enumerate(graph)\n",
    "    ]\n",
    "    with open(save_filepath, \"wb\") as file:\n",
    "        pickle.dump(gdata_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = \"path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(graph_path, 'rb') as f:\n",
    "    gdata_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata_list[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdata_list = load_graphs(graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = gdata_list[0][0]\n",
    "graph_dict = gdata_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(gdata_list[0][0]) == DGLHeteroGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_filepath = \"path\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_graphs_python(save_filepath, graph, graph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_filepath, \"wb\") as file:\n",
    "        pickle.dump(gdata_list, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving testing fixtures graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole graph fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapped_transactions_custom():\n",
    "    transactions_dict = {\n",
    "        \"user_id\": {\n",
    "            \"0\": 0,\n",
    "            \"1\": 0,\n",
    "            \"2\": 0,\n",
    "            \"3\": 0,\n",
    "            \"4\": 0,\n",
    "            \"5\": 1,\n",
    "            \"6\": 1,\n",
    "            \"7\": 1,\n",
    "            \"8\": 1,\n",
    "            \"9\": 1,\n",
    "            \"10\": 2,\n",
    "            \"11\": 2,\n",
    "            \"12\": 2,\n",
    "            \"13\": 2,\n",
    "            \"14\": 2,\n",
    "            \"15\": 3,\n",
    "            \"16\": 3,\n",
    "            \"17\": 3,\n",
    "            \"18\": 3,\n",
    "            \"19\": 3,\n",
    "            \"20\": 4,\n",
    "        },\n",
    "        \"item_id\": {\n",
    "            \"0\": 0,\n",
    "            \"1\": 1,\n",
    "            \"2\": 2,\n",
    "            \"3\": 2,\n",
    "            \"4\": 3,\n",
    "            \"5\": 0,\n",
    "            \"6\": 1,\n",
    "            \"7\": 2,\n",
    "            \"8\": 5,\n",
    "            \"9\": 3,\n",
    "            \"10\": 0,\n",
    "            \"11\": 1,\n",
    "            \"12\": 2,\n",
    "            \"13\": 4,\n",
    "            \"14\": 3,\n",
    "            \"15\": 7,\n",
    "            \"16\": 1,\n",
    "            \"17\": 2,\n",
    "            \"18\": 6,\n",
    "            \"19\": 3,\n",
    "            \"20\": 8,\n",
    "        },\n",
    "        \"time\": {\n",
    "            \"0\": 1453939200,\n",
    "            \"1\": 1453039200,\n",
    "            \"2\": 1453032200,\n",
    "            \"3\": 1453132200,\n",
    "            \"4\": 1453132200,\n",
    "            \"5\": 1453939201,\n",
    "            \"6\": 1453039202,\n",
    "            \"7\": 1453032203,\n",
    "            \"8\": 1453132204,\n",
    "            \"9\": 1453132205,\n",
    "            \"10\": 1453939206,\n",
    "            \"11\": 1453039207,\n",
    "            \"12\": 1453032208,\n",
    "            \"13\": 1453132209,\n",
    "            \"14\": 1453132210,\n",
    "            \"15\": 1453939211,\n",
    "            \"16\": 1453039212,\n",
    "            \"17\": 1453032213,\n",
    "            \"18\": 1453132214,\n",
    "            \"19\": 1453132215,\n",
    "            \"20\": 1453939216,\n",
    "        },\n",
    "    }\n",
    "    transactions_df = pd.DataFrame(transactions_dict)\n",
    "    return transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_custom = mapped_transactions_custom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_custom = generate_graph_dgsr(transactions_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = \"../src/tests/fixtures/graphs/graph_custom.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(graph_path, 'wb') as f:\n",
    "    pickle.dump(graph_custom, f, protocol=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsets graph fixtures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, val_list, test_list, _ = preprocess_dgsr(\n",
    "            transactions_custom,\n",
    "            graph_custom,\n",
    "            50,\n",
    "            50,\n",
    "            3,\n",
    "            True,\n",
    "            True,\n",
    "            False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list, _, _, predict_list = preprocess_dgsr(\n",
    "            transactions_custom,\n",
    "            graph_custom,\n",
    "            50,\n",
    "            50,\n",
    "            3,\n",
    "            False,\n",
    "            False,\n",
    "            True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [train_list, val_list, test_list, predict_list]\n",
    "subnames = [\"train\", \"val\", \"test\", \"predict\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subname, subset in zip(subnames, subsets):\n",
    "    save_args = {\"file_extension\": \"pkl\"}\n",
    "    subset_dataset = DGSRSubGraphsDataSet(f\"../src/tests/fixtures/graphs/{subname}_subgraphs\", save_args)\n",
    "    subset_dataset._save(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negatives samples fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_custom = mapped_transactions_custom()\n",
    "negatives = sample_negatives_dgsr(transactions_custom)\n",
    "negatives.to_csv(\"../src/tests/fixtures/dataframes/negatives.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subgraphs lists fixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_custom():\n",
    "    graph_path = \"../src/tests/fixtures/graphs/graph_custom.pkl\"\n",
    "    with open(graph_path, \"rb\") as f:\n",
    "        graph = pickle.load(f)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subgraphs_lists_custom():\n",
    "    \"\"\"Example function for creating a custom train/val/test/predict subgraphs lists for testing purposes. Only\n",
    "    for fixtures reconstruction purposes.\"\"\"\n",
    "    transactions_custom = mapped_transactions_custom()\n",
    "    full_graph_custom = graph_custom()\n",
    "    _, val_list, test_list, _ = preprocess_dgsr(\n",
    "        transactions_custom,\n",
    "        full_graph_custom,\n",
    "        50,\n",
    "        50,\n",
    "        3,\n",
    "        True,\n",
    "        True,\n",
    "        False,\n",
    "    )\n",
    "    train_list, _, _, predict_list = preprocess_dgsr(\n",
    "        transactions_custom,\n",
    "        full_graph_custom,\n",
    "        50,\n",
    "        50,\n",
    "        3,\n",
    "        False,\n",
    "        False,\n",
    "        True,\n",
    "    )\n",
    "    subsets = [train_list, val_list, test_list, predict_list]\n",
    "    subnames = [\"train\", \"val\", \"test\", \"predict\"]\n",
    "    return subsets, subnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subgraphs_lists_pickles_custom():\n",
    "    \"\"\"Example function for creating a custom train/val/test/predict subgraphs lists pickles for testing purposes. Only\n",
    "    for fixtures reconstruction purposes.\"\"\"\n",
    "    subsets, subnames = create_subgraphs_lists_custom()\n",
    "    sub_dict = dict(zip(subnames, subsets))\n",
    "    for subname in subnames:\n",
    "        save_path = f\"../src/tests/fixtures/graphs/{subname}_subgraphs_lists.pkl\"\n",
    "        with open(save_path, \"wb\") as file:\n",
    "            pickle.dump(sub_dict[subname], file, protocol=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_subgraphs_lists_pickles_custom()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('gid-gnns')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e87cc64cfde56b8b55d0221d0c3db975499f0cbfa29fbbe10a13999eb0ccf56e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
